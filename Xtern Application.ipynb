{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's take a look at the data set we have to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"data.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Address</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IUPUI</td>\n",
       "      <td>415 Porto Alegre St, Indianapolis, IN 46202</td>\n",
       "      <td>Housing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Speak Easy</td>\n",
       "      <td>5255 Winthrop Ave #110, Indianapolis, IN 46220</td>\n",
       "      <td>Coworking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zWORKS</td>\n",
       "      <td>85 E Cedar St #1502, Zionsville, IN 46077</td>\n",
       "      <td>Coworking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Launch Fishers</td>\n",
       "      <td>12175 Visionary Way, Fishers, IN 46038</td>\n",
       "      <td>Coworking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Industrious Mass Ave</td>\n",
       "      <td>350 Massachusetts Ave Suite 300, Indianapolis,...</td>\n",
       "      <td>Coworking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Launch Indy</td>\n",
       "      <td>525 S Meridian St, Indianapolis, IN 46225</td>\n",
       "      <td>Coworking</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Name                                            Address  \\\n",
       "0                 IUPUI        415 Porto Alegre St, Indianapolis, IN 46202   \n",
       "1        The Speak Easy     5255 Winthrop Ave #110, Indianapolis, IN 46220   \n",
       "2                zWORKS          85 E Cedar St #1502, Zionsville, IN 46077   \n",
       "3        Launch Fishers             12175 Visionary Way, Fishers, IN 46038   \n",
       "4  Industrious Mass Ave  350 Massachusetts Ave Suite 300, Indianapolis,...   \n",
       "5           Launch Indy          525 S Meridian St, Indianapolis, IN 46225   \n",
       "\n",
       "        Type  \n",
       "0    Housing  \n",
       "1  Coworking  \n",
       "2  Coworking  \n",
       "3  Coworking  \n",
       "4  Coworking  \n",
       "5  Coworking  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like we're basically just given the options in this data set, but to start out let's check out the potential commute times for each of these businesses given the housing location. We will use the GoogleMaps API for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_housing' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-74979d37f33e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mlatlong\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeocoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgoogle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"AIzaSyCwat20hKRIFms7igGMAFjTuplaRozFoMU\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatlng\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mhousing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgeocoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgoogle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_housing\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Address'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"AIzaSyCwat20hKRIFms7igGMAFjTuplaRozFoMU\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatlng\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_housing' is not defined"
     ]
    }
   ],
   "source": [
    "import geocoder\n",
    "\n",
    "latlong = []\n",
    "\n",
    "for row in df['Address']:\n",
    "    latlong.append((geocoder.google(row, key=\"AIzaSyCwat20hKRIFms7igGMAFjTuplaRozFoMU\")).latlng)\n",
    "    \n",
    "housing = geocoder.google(df['Address'][0], key=\"AIzaSyCwat20hKRIFms7igGMAFjTuplaRozFoMU\").latlng\n",
    "\n",
    "\n",
    "df['Latlng'] = latlong\n",
    "df_housing = df[df.Type == \"Housing\"]\n",
    "df_coworking = df[df.Type == \"Coworking\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import googlemaps\n",
    "\n",
    "gmaps = googlemaps.Client(key='AIzaSyCwat20hKRIFms7igGMAFjTuplaRozFoMU')\n",
    "from datetime import datetime\n",
    "\n",
    "time = []\n",
    "distance = []\n",
    "\n",
    "\n",
    "for x in df_coworking['Latlng']:\n",
    "    now = datetime.now()\n",
    "    directions_result = gmaps.directions(x,housing,\n",
    "                                     mode=\"driving\",\n",
    "                                     departure_time=now\n",
    "                                    )\n",
    "    distance.append(directions_result[0]['legs'][0]['distance']['text'])\n",
    "    time.append(directions_result[0]['legs'][0]['duration']['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that some of these are closer than others to the housing location at IUPUI, but this is not the end-all be-all factor for decision making. Our goal is to minimize the total distance traveled, so let's check out where else these people might be going to. First, we should consider the makeup of a typical week. By the prompt, \"A sample 10-week activities plan includes a weekly group dinner at different restaurants around Indianapolis, a biweekly sport, music, gaming, and art event, one big conference or Ted Talk event.\"\n",
    "\n",
    "The major categories here are:\n",
    "1. Restaurants\n",
    "2. Sports\n",
    "3. Music\n",
    "4. Gaming\n",
    "5. Art\n",
    "6. Conference/Tedtalk\n",
    "\n",
    "We will manually compile a list of these events from google/EventBrite/DowntownIndy. I looked into API calls to EventBrite to populate this list, but since EventBrite doesn't offer general restaurants we would still have to manually populate that category, and at that point it would introduce bias to the models to have some categories with strictly limited data and some categories with an abundance.\n",
    "\n",
    "The list of events is imported below, with the category for each listed in the \"category\" column. In addition, we have set the 10-week period for filtering events to be from October 16 until December 25. This is out of convenience more than anything else, we must assume some time period in order to find concrete events, but we could change these bounds and our approach would work for any given period of time. I have not included physical dates for these events. The reason for this is time constraints, it took me many hours to simply make this excel document and I don't have time to make a system to identify date conflicts in proposed schedules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_events = pd.read_excel(\"events.xlsx\")\n",
    "latlong = []\n",
    "for row in df_events.Address:\n",
    "    latlong.append((geocoder.google(row, key=\"AIzaSyCwat20hKRIFms7igGMAFjTuplaRozFoMU\")).latlng)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_events['Latlng'] = latlong\n",
    "df_events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This list of events is far from exhaustive and if I had more time I would look into ways to automate the process for all categories to populate good data, but I'm more interested in demonstrating ability to analyze this data and solve a concrete problem than demonstrating ability to use API calls to populate a dataset and don't have time to do it all. It is not exhaustive, but you can see from the map below that the 31 event venues in this dataset are reasonably well-dispersed over the Indianapolis metropolitan area. They are definitely centered downtown, but so are most events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gmaps as gmap\n",
    "\n",
    "gmap.configure(api_key = 'AIzaSyCwat20hKRIFms7igGMAFjTuplaRozFoMU')\n",
    "\n",
    "df_restaurants = df_events[df_events.Category == 'Restaurant']\n",
    "df_sports = df_events[df_events.Category == 'Sports']\n",
    "df_art = df_events[df_events.Category == 'Art']\n",
    "df_music = df_events[df_events.Category == 'Music']\n",
    "df_games = df_events[df_events.Category == 'Games']\n",
    "df_conference = df_events[df_events.Category == 'Conference']\n",
    "\n",
    "\n",
    "\n",
    "housing_layer = gmap.symbol_layer(\n",
    "    df_housing['Latlng'], fill_color='aqua', stroke_color='aqua', scale=2\n",
    ")\n",
    "\n",
    "coworking_layer = gmap.symbol_layer(\n",
    "    df_coworking['Latlng'], fill_color='red', stroke_color='red', scale=4\n",
    ")\n",
    "sports_layer = gmap.symbol_layer(\n",
    "    df_sports['Latlng'], fill_color='blue', stroke_color='blue', scale=2\n",
    ")\n",
    "restaurant_layer = gmap.symbol_layer(\n",
    "    df_restaurants['Latlng'], fill_color='green', stroke_color='green', scale=2\n",
    ")\n",
    "art_layer = gmap.symbol_layer(\n",
    "    df_art['Latlng'], fill_color='purple', stroke_color='purple', scale=2\n",
    ")\n",
    "games_layer = gmap.symbol_layer(\n",
    "    df_games['Latlng'], fill_color='gray', stroke_color='gray', scale=2\n",
    ")\n",
    "music_layer = gmap.symbol_layer(\n",
    "    df_music['Latlng'], fill_color='black', stroke_color='black', scale=2\n",
    ")\n",
    "conference_layer = gmap.symbol_layer(\n",
    "    df_conference['Latlng'], fill_color='white', stroke_color='white', scale=2\n",
    ")\n",
    "coord = (39.83,-86.17)\n",
    "fig = gmap.figure(center = coord, zoom_level = 10)\n",
    "fig.add_layer(coworking_layer)\n",
    "fig.add_layer(housing_layer)\n",
    "fig.add_layer(sports_layer)\n",
    "fig.add_layer(music_layer)\n",
    "fig.add_layer(games_layer)\n",
    "fig.add_layer(restaurant_layer)\n",
    "fig.add_layer(conference_layer)\n",
    "fig.add_layer(art_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the big red dots correspond to the housing candidates, and the smaller multicolored events to various events. From this picture it's pretty clear that the lower 2 candidates are much closer to the average event than the upper 3. A larger dataset would give the appearance of a more balanced spread of location, since more dots would be on the map, but the ratio heavily skewed in favor of downtown events will almost certainly have the bottom 2 locations retain their superiority in terms of distance in the average case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first discuss which kinds of data we will use to make these claims. For each route between two points, google gives us a distance and the expected transit time given current traffic patterns. We will prioritize the distance data over the time data, as the time data is likely skewed by the time of day the script runs (running it at night would give travel times without traffic, running it during the day would give times with traffic), and so this would be unreliable for locations hampered by traffic. In addition, Xterns may be on foot going to many of these places downtown, so street distance (ignoring traffic) would be a better estimate of travel time. Lastly, to simplify calculations, we will be working with one-way distances. It shouldn't change any ranking, just scales the numbers down a bit. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a list of activities, we can begin to find the average distance travelled from each location. However, given our limited hand-scraped data set, with barely enough entries to populate a full 10-week schedule, it might be better to transform this problem to a lower dimensional space. Rather than thinking of it as minimizing the average distance traveled over any full 10-week period, we can simply minimize the average distance traveled during the average week. Therefore, our strategy is relatively simple: given any 1-week period, by definition with an average of 1 weekly dinner, .5 sports events, .5 arts events, .5 music events, .5 game events, and .1 conference, select the location with the minimum distance travelled to these events. We can express this mathematically as $x_{dinner} + \\frac{x_{sports}}{2} + \\frac{x_{arts}}{2} + \\frac{x_{music}}{2} + \\frac{x_{game}}{2} + \\frac{x_{conference}}{10}$, where the various $x_{subscript}$ denote the distance from a given coworking location candidate to each activity.\n",
    "\n",
    "Now, we need to use the data we have to find these $x$. The naiive approach would be to find the distance to each item in the category and average the distances. Alternatively, we can weight likeliood of selection by quality, making the higher-rated locations more likely to be selected. This seems plausible to me, without given prior knowledge of event quality it makes sense to use internet reviews as a benchmark when picking a schedule. We will use google reviews for this purpose. If we are not able to find a rating for a venue, this will not count for or against its chances and it will be assigned a probability of $\\frac{1}{n}$ rather than weighted. This approach would work better with a larger data set, but this notebook should convey the general idea of how this approach would work with good data with a healthy sample size, which I don't know how we would be supposed to acquire given the time restrictions of this project. Instead, I chose to focus on the analysis of the data we do have to highlight the spirit of the optimization problem inspired by the prompt. \n",
    "\n",
    "Now, let's compute these distances for each coworking location. Starting with location 1, we have the distance from this location to each element of each category, in turn, in the script below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_restaurants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's make a list of the distances from location 1 to each coordinate on the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = [0,0,0,0,0,0]\n",
    "location[0] = df_coworking['Latlng'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_rest = [[],[],[],[],[]]\n",
    "for row in df_restaurants['Latlng']:\n",
    "    now = datetime.now()\n",
    "    directions_result = gmaps.directions(row,location[0],\n",
    "                                     mode=\"driving\",\n",
    "                                     departure_time=now\n",
    "                                    )\n",
    "    distance_rest[0].append(directions_result[0]['legs'][0]['distance']['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(distance_rest[0])):\n",
    "    distance_rest[0][i] = float(str.split(distance_rest[0][i])[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to compute the weighted average, we will simply multiply each term by its corresponding rating, and then divide each by the normalizing constant of the sum of the ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = 0\n",
    "for i in range(len(distance_rest[0])):\n",
    "    mean += (distance_rest[0][i]*df_restaurants.Rating[i])\n",
    "    \n",
    "mean = mean/sum(df_restaurants.Rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurant_distances = []\n",
    "restaurant_distances.append(mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have this weighted average for restaurants for location 1, let's repeat the process for each other category. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_sports = [[],[],[],[],[]]\n",
    "for row in df_sports['Latlng']:\n",
    "    now = datetime.now()\n",
    "    directions_result = gmaps.directions(row,location[0],\n",
    "                                     mode=\"driving\",\n",
    "                                     departure_time=now\n",
    "                                    )\n",
    "    distance_sports[0].append(directions_result[0]['legs'][0]['distance']['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(distance_sports[0])):\n",
    "    distance_sports[0][i] = float(str.split(distance_sports[0][i])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = 0\n",
    "for i in range(len(distance_sports[0])):\n",
    "    mean += (distance_sports[0][i]*df_sports.Rating[10+i])\n",
    "    \n",
    "mean = mean/sum(df_sports.Rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sports_distances = []\n",
    "sports_distances.append(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_art"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_art = [[],[],[],[],[]]\n",
    "for row in df_art['Latlng']:\n",
    "    now = datetime.now()\n",
    "    directions_result = gmaps.directions(row,location[0],\n",
    "                                     mode=\"driving\",\n",
    "                                     departure_time=now\n",
    "                                    )\n",
    "    distance_art[0].append(directions_result[0]['legs'][0]['distance']['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(distance_art[0])):\n",
    "    distance_art[0][i] = float(str.split(distance_art[0][i])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = 0\n",
    "for i in range(len(distance_art[0])):\n",
    "    mean += (distance_art[0][i]*df_art.Rating[15+i])\n",
    "    \n",
    "mean = mean/sum(df_art.Rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "art_distances = []\n",
    "art_distances.append(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_games = [[],[],[],[],[]]\n",
    "for row in df_games['Latlng']:\n",
    "    now = datetime.now()\n",
    "    directions_result = gmaps.directions(row,location[0],\n",
    "                                     mode=\"driving\",\n",
    "                                     departure_time=now\n",
    "                                    )\n",
    "    distance_games[0].append(directions_result[0]['legs'][0]['distance']['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(distance_games[0])):\n",
    "    distance_games[0][i] = float(str.split(distance_games[0][i])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = 0\n",
    "for i in range(len(distance_games[0])):\n",
    "    mean += (distance_games[0][i]*df_games.Rating[20+i])\n",
    "    \n",
    "mean = mean/sum(df_games.Rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games_distances = []\n",
    "games_distances.append(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_music = [[],[],[],[],[]]\n",
    "for row in df_music['Latlng']:\n",
    "    now = datetime.now()\n",
    "    directions_result = gmaps.directions(row,location[0],\n",
    "                                     mode=\"driving\",\n",
    "                                     departure_time=now\n",
    "                                    )\n",
    "    distance_music[0].append(directions_result[0]['legs'][0]['distance']['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(distance_music[0])):\n",
    "    distance_music[0][i] = float(str.split(distance_music[0][i])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = 0\n",
    "for i in range(len(distance_music[0])):\n",
    "    mean += (distance_music[0][i]*df_music.Rating[25+i])\n",
    "    \n",
    "mean = mean/sum(df_music.Rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "music_distances = []\n",
    "music_distances.append(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_conference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we only have one conference, this is a trivial case where the mean distance for the category will just be the distance from each location to this conference. The below script finds this for location 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "directions_result = gmaps.directions(df_conference['Latlng'][30],location[0],\n",
    "                                     mode=\"driving\",\n",
    "                                     departure_time=now\n",
    "                                    )\n",
    "dist = directions_result[0]['legs'][0]['distance']['text']\n",
    "conference_distances = []\n",
    "conference_distances.append(float(str.split(dist)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have gone through the motions of creating our $x$ for each category, we can compute the expected distance travelled from location 1 by following the expression from above. Substituting our values from above, we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expectation = restaurant_distances[0] + .5*sports_distances[0]+ .5*art_distances[0] + .5*music_distances[0] + .5*games_distances[0] + .1*conference_distances[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurant_distances[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the expected distance travelled to events on the schedule, but we also have to commute to the housing location 5 days a week. Therefore, we must add 5 of these onto the distance, as shown in the below script. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = geocoder.google(df_housing['Address'][0], key=\"AIzaSyCwat20hKRIFms7igGMAFjTuplaRozFoMU\").latlng\n",
    "now = datetime.now()\n",
    "directions_result = gmaps.directions(housing,location[0],\n",
    "                                     mode=\"driving\",\n",
    "                                     departure_time=now\n",
    "                                    )\n",
    "commute = (directions_result[0]['legs'][0]['distance']['text'])\n",
    "commute = float(str.split(commute)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_distance = []\n",
    "total_distance.append(expectation + 5*commute)\n",
    "total_distance[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After all that work, this slightly-under-58-mile total is our final product for location 1, the total expected distance travelled in an average week spent at location 1 during the 10-week period. Now, let's find these expected distances for the other 4 locations as well. Once we have this, the smallest total distance among locations will be crowned the most central location, and will be our selection as the best coworking space to choose. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_rest = [[],[],[],[],[]]\n",
    "distance_sports = [[],[],[],[],[]]\n",
    "distance_art = [[],[],[],[],[]]\n",
    "distance_games = [[],[],[],[],[]]\n",
    "distance_music = [[],[],[],[],[]]\n",
    "\n",
    "restaurant_distances = []\n",
    "sports_distances = []\n",
    "art_distances = []\n",
    "games_distances = []\n",
    "music_distances = []\n",
    "conference_distances = []\n",
    "\n",
    "expectation = [0,0,0,0,0]\n",
    "commute = [0,0,0,0,0]\n",
    "total_distance = [0,0,0,0,0]\n",
    "\n",
    "    \n",
    "for j in range(5):\n",
    "    location[j] = df_coworking['Latlng'][j+1]\n",
    "    \n",
    "    ###Restaurants#################################################################################################\n",
    "    for row in df_restaurants['Latlng']:\n",
    "        now = datetime.now()\n",
    "        directions_result = gmaps.directions(row,location[j],\n",
    "                                     mode=\"driving\",\n",
    "                                     departure_time=now\n",
    "                                    )\n",
    "        distance_rest[j].append(directions_result[0]['legs'][0]['distance']['text'])\n",
    "        \n",
    "    for i in range(len(distance_rest[j])):\n",
    "        distance_rest[j][i] = float(str.split(distance_rest[j][i])[0])\n",
    "    \n",
    "    mean = 0\n",
    "    for i in range(len(distance_rest[j])):\n",
    "        mean += (distance_rest[j][i]*df_restaurants.Rating[i]) \n",
    "    mean = mean/sum(df_restaurants.Rating)\n",
    "    restaurant_distances.append(mean)\n",
    "    \n",
    "    ###And now for sports#########################################################################################\n",
    "    for row in df_sports['Latlng']:\n",
    "        now = datetime.now()\n",
    "        directions_result = gmaps.directions(row,location[j],\n",
    "                                     mode=\"driving\",\n",
    "                                     departure_time=now\n",
    "                                    )\n",
    "        distance_sports[j].append(directions_result[0]['legs'][0]['distance']['text'])\n",
    "    \n",
    "    for i in range(len(distance_sports[j])):\n",
    "        distance_sports[j][i] = float(str.split(distance_sports[j][i])[0])\n",
    "        \n",
    "    mean = 0\n",
    "    for i in range(len(distance_sports[j])):\n",
    "        mean += (distance_sports[j][i]*df_sports.Rating[10+i])\n",
    "    mean = mean/sum(df_sports.Rating)\n",
    "    sports_distances.append(mean)\n",
    "    \n",
    "    ###Art########################################################################################################\n",
    "    for row in df_art['Latlng']:\n",
    "        now = datetime.now()\n",
    "        directions_result = gmaps.directions(row,location[j],\n",
    "                                     mode=\"driving\",\n",
    "                                     departure_time=now\n",
    "                                    )\n",
    "        distance_art[j].append(directions_result[0]['legs'][0]['distance']['text'])\n",
    "    \n",
    "    for i in range(len(distance_art[j])):\n",
    "        distance_art[j][i] = float(str.split(distance_art[j][i])[0])\n",
    "    \n",
    "    mean = 0\n",
    "    for i in range(len(distance_art[j])):\n",
    "        mean += (distance_art[j][i]*df_art.Rating[15+i])  \n",
    "    mean = mean/sum(df_art.Rating)\n",
    "    art_distances.append(mean)\n",
    "    \n",
    "    ###Games #####################################################################################################\n",
    "    for row in df_games['Latlng']:\n",
    "        now = datetime.now()\n",
    "        directions_result = gmaps.directions(row,location[j],\n",
    "                                     mode=\"driving\",\n",
    "                                     departure_time=now\n",
    "                                    )\n",
    "        distance_games[j].append(directions_result[0]['legs'][0]['distance']['text'])\n",
    "    for i in range(len(distance_games[j])):\n",
    "        distance_games[j][i] = float(str.split(distance_games[j][i])[0])\n",
    "        \n",
    "    mean = 0\n",
    "    for i in range(len(distance_games[j])):\n",
    "        mean += (distance_games[j][i]*df_games.Rating[20+i])\n",
    "    mean = mean/sum(df_games.Rating)\n",
    "    games_distances.append(mean)\n",
    "    \n",
    "    ###Music ###################################################################################################\n",
    "    \n",
    "    for row in df_music['Latlng']:\n",
    "        now = datetime.now()\n",
    "        directions_result = gmaps.directions(row,location[j],\n",
    "                                     mode=\"driving\",\n",
    "                                     departure_time=now\n",
    "                                    )\n",
    "        distance_music[j].append(directions_result[0]['legs'][0]['distance']['text'])\n",
    "        \n",
    "    for i in range(len(distance_music[j])):\n",
    "        distance_music[j][i] = float(str.split(distance_music[j][i])[0])\n",
    "    \n",
    "    mean = 0\n",
    "    for i in range(len(distance_music[j])):\n",
    "        mean += (distance_music[j][i]*df_music.Rating[25+i]) \n",
    "    mean = mean/sum(df_music.Rating)\n",
    "    music_distances.append(mean)\n",
    "    \n",
    "    ###Conference#################################################################################################\n",
    "    now = datetime.now()\n",
    "    directions_result = gmaps.directions(df_conference['Latlng'][30],location[j],\n",
    "                                     mode=\"driving\",\n",
    "                                     departure_time=now\n",
    "                                    )\n",
    "    dist = directions_result[0]['legs'][0]['distance']['text']\n",
    "    conference_distances.append(float(str.split(dist)[0]))\n",
    "    \n",
    "    ###Expectation########################################################################################\n",
    "    expectation[j] = restaurant_distances[j] + .5*sports_distances[j]+ .5*art_distances[j] + .5*music_distances[j] + .5*games_distances[j] + .1*conference_distances[j]\n",
    "    now = datetime.now()\n",
    "    directions_result = gmaps.directions(housing,location[j],\n",
    "                                     mode=\"driving\",\n",
    "                                     departure_time=now\n",
    "                                    )\n",
    "    commute[j] = (directions_result[0]['legs'][0]['distance']['text'])\n",
    "    commute[j] = float(str.split(commute[j])[0])\n",
    "    \n",
    "    total_distance[j]=(expectation[j] + 5*commute[j])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "minimum = min(total_distance)\n",
    "argmin = np.argmin(total_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "argmin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we can clearly see that the minimum distance, by, far, is traveled by selecting the 5th location, Launch indy. We barely have enough events to make a full 10-week schedule, but here's what we would suggest, in addition to selecting Launch Indy as the coworking space:\n",
    "\n",
    "Week 1: The Eagle as group dinner, WWE Smackdown (sports), and Black&Blue (art) \\\n",
    "Week 2: Goodwood Indy (Dinner), Escape Room Indy (Games), and John Legend Tour(Music) \\\n",
    "Week 3: The Oakmont(Dinner), Colts Game(Sports), and Newfields(Art) \\\n",
    "Week 4: Tinker Street(Dinner), Duckpin bowling(Games), and Cheef Keef(Music) \\\n",
    "Week 5: Slapfish(Dinner), Pacers Game(Sports), and Ghost Stories at Tibbs(Art) \\\n",
    "Week 6: Modita (Dinner), Whodunit?(Games), and Vineyard Live Music(Music) \\\n",
    "Week 7: Livery(Dinner), Indy Eleven Game(Sports), and Charlie and the Chocolate Factory(Art) \\\n",
    "Week 8: Bluebeard(Dinner), Karting(Games), and Black Violin Concerto(Music) \\\n",
    "Week 9: Comida(Dinner), Big 10 Championship(Sports), IRT Christmas Carol(Art), and Indiana Conference for Women \\\n",
    "Week 10: Nada(Dinner), Wednesday Night Trivia(Games), and Andrew McMahon(Music)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
